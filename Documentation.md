

# Introduction #

Icegem is an extension for in-memory data grid [GemFire Enterprise](http://community.gemstone.com/display/gemfire/GemFire+Enterprise)<sup>tm</sup> which provides serialization mechanism for domain classes that will be stored in the GemFire out of the box and eliminates the needs to take care of that routine yet unavoidable task. It guarantees best performance in compare with standard java serialization, supports versioning of the domain model classes and cases where part of the classes have already been serializable.

This library also provides extensions and fill gaps in GemFire API (e.g. supports [paginated queries](Documentation#Paginated_Queries.md), [bucket oriented query service](Documentation#Bucket_oriented_query_service.md), [smart expiration](Documentation#Smart_expiration.md), etc.).

# Build description #

  1. getting source:  svn checkout http://icegem.googlecode.com/svn/trunk/icegem-read-only
  1. building artifacts: mvn install
> > p.s. to build a single module: cd module\_folder, mvn install
  1. testing: mvn test
  1. integration testing: mvn verify

**Note**: some integration test require gemfire license more then embedded. You can specify a custom gemfire license instead of embedded in a main `pom.xml` file.


# Automatic serialization with versioning support #

The library provides mechanism to automatically generate GemFire DataSerializer classes for model objects.

## Auto serializable annotation ##

Each class that will be auto serialized should be annotated with `@AutoSerializeble` annotation. This annotations contains the following properties:
  * `dataSerializerID` - an unique id for generated data serializer (required). This id should be the same for all versions of a class;
  * `versionHistoryLength` - a number of bean versions (except current) for which class model hash codes will be stored in DataSerializer. This property value should be positive, by default `versionHistoryLength = 2`.


## Bean versioning ##

Icegem supports data model versioning. It's achieved by using two annotations `@BeanVersion` and `@SinceVersion`.

In accordance to serialization/deserialization process we impose some restrictions for classes that use versioning:

  * already existed in previous versions of the class fields can't be deleted in new versions;
  * a field that doesn't exist in the first version should be annotated with `@SinceVersion` specifying version from which this field appeared. `@SinceVersion` value should be positive;
  * all versions of a class should have annotation `@AutoSerializable` with the same `dataSerializerID`.

These restrictions refer not only to @AutoSerializable class but also to it's superclasses (except java.lang.Object).
See domain class [examples](Documentation#Domain_class_examples.md) for more details.

## Domain class requirements ##

Icegem imposes some constraints on a domain classes. Partially they are inherited from requirements on DataSerializable implementation and partially they introduced by need to support versioining of model classes :
  * Class should have a public no-arguments constructor;
  * if the class extends another class, superclass should either satisfy this constrains or it should be serializable;
  * nested classes for this class should not be serializable;
  * all class fields should have getters and setters;
  * Class has to comply with JavaBean property definition requirements

**Note**: Object should not contain circular references. See section [Autodetection of circular references](Documentation#Autodetection_of_circular_references.md) for more information about built-in mechanism for detecting circular references.

Each class that will be auto serialized should be annotated with annotations:
  * `@AutoSerializable` - a main annotation that marks auto serializable classes. Additional information about this annotation can be found [here](Documentation#Auto_serializeble_annotation.md);
  * `@BeanVersion` - specifies version of the current class via a required property `value`. This version should be positive. For more details about domain class versioning see this [section](Documentation#Bean_versioning.md).

See domain class [examples](Documentation#Domain_class_examples.md) for more details.


## Recognition of class model changes ##

Using versioning each class may have arbitrary number of versions. All generated by Icegem library data serializers has build-in functionality for detecting inconsistency between class models using some king of hash code based on class fields that are included into particular class version.

Property `versionHistoryLength` of annotation `@AutoSerializable` specifies a number of bean versions (except current) for which class model hash codes will be stored in DataSerializer. During deserialization data serializer compares class models and if they are different, a `ClassCastException` will be thrown.

## Domain class examples ##

The first version of the class `Company`:
```
package com.googlecode.icegem.serialization.versioning.beans.previousversion.beanv1;

import com.googlecode.icegem.serialization.AutoSerializable;
import com.googlecode.icegem.serialization.BeanVersion;

@AutoSerializable(dataSerializerID = 1412)
@BeanVersion(1)
public class Company {
    private int id;

    public Company() {
    }

    public int getId() {
        return id;
    }

    public void setId(int id) {
        this.id = id;
    }
    @Override
    public String toString() {
        return "Company{" +
                "id=" + id +
                '}';
    }
}
```
The second version of the class `Company` where a new field `name` has been added and `versionHistoryLength` has been set to custom value (default is 5):
```
package com.googlecode.icegem.serialization.versioning.beans.previousversion.beanv2;

import com.googlecode.icegem.serialization.AutoSerializable;
import com.googlecode.icegem.serialization.BeanVersion;
import com.googlecode.icegem.serialization.SinceVersion;

@AutoSerializable(dataSerializerID = 1412, versionHistoryLength = 2)
@BeanVersion(2)
public class Company {
    private int id;
    
    private String name;

    public Company() {
    }

    public int getId() {
        return id;
    }

    public void setId(int id) {
        this.id = id;
    }

    @SinceVersion(2)
    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    @Transient
    public String getCompositeKey(){
         return this.id + this.name;
    }

    @Override
    public String toString() {
        return "Company{" +
                "id=" + id +
                ", name='" + name + '\'' +
                '}';
    }
}
```

## Registrar Bean ##

This is a [Spring](http://www.springsource.org/) bean for using in spring-based projects that helps to find all classes for which serialization is required. `AutoSerializableRegistrarBean` scans specified domain model packages for classes annotated with `@AutoSerializable` annotation and passes founded classes to [Hierarchy Registry](Documentation#Hierarchy_Registry.md) class for further  generation and registration of data serializers. Icegem library integration using Spring you can find in this [section](Documentation#Library_integration_using_Spring.md). There is also a [section](Documentation#Manual_library_integration.md), describes how to integrate the Icegem library manually.

## Autodetection of circular references ##

If classes contain circular references, during serialization of such classes a stack overflow error will be thrown.
Icegem support a build-in mechanism for detecting circular references. By default it is disabled. It can be enabled by using java property `icegem.serialization.trace.methodframes`. This property can be set via JVM parameters:
```
-Dicegem.serialization.trace.methodframes=true
```
or from the code using the following command:
```
import com.googlecode.icegem.serialization.codegen.MethodFrameCounter;
...
System.setProperty(MethodFrameCounter.SYSTEM_PROPERTY_NAME, "true");
```

## Java native serialization ##

## DataSerializer registration distribution ##
By default registration of any DataSerializable type in GemFire is distributed across DS. icegem allows to control and disable the distribution mechanism. This is done purposely to enforce strong discipline of class management. While in simple case automatic registration simplifies system management, in complex system it may cause hardly identifiable glitches and problems.

By default automatic distribution is ENABLED.

To disable it, use system property

```
  -Dicegem.serialization.distribute.registration.disabled=true
```

## Library integration ##

There are two ways of integrating the Icegem library into a progect: via spring and manually

icegem-core contains a class `AutoSerializableRegistrarBean` that can be used for registration of classes with annotation @AutoSerializable. To use it, you should register this bean in spring like:

  1. define bean with class  com.griddynamics.gemfire.serialization.spring.AutoSerializableRegistrarBean
> > e.g.
```
<bean id="icegem"  class="com.googlecode.icegem.serialization.spring.AutoSerializableRegistrarBean" scope="singleton">
    ...
</bean>
```
  1. set property which point to domain model package
> > e.g.
```
<property name="scanPackages">
    <list>
        <value>com.griddynamics.gemfire.serialization.test.domain</value>
    </list>
</property>
```
  1. add javassist.jar, icegem-core.jar to ClassPath.

To use  library without spring:

  1. add javassist.jar, icegem-core.jar to ClassPath
  1. call `HierarchyRegistry.registerAll` with two arguments: class loader and list of domain classes that meet the [requirements](Documentation#Domain_class_requirements.md) for use in the Icegem library.

## Mixing auto and manual serialization ##

In a project both annotated and casual serializable classes (implementing DataSerializable/Serializable or extending DataSerilizer) can be used.

## Performance characteristics ##

[Thrift-protobuf-compare](http://code.google.com/p/thrift-protobuf-compare/) project were used for benchmark testing.
The data value used in the benchmark:

```
MediaContent {

   media = Media {
      uri = "http://javaone.com/keynote.mpg"
      title = "Javaone Keynote"
      width = 640
      height = 480
      format = "video/mpg4"
      duration = 18000000    // half hour in milliseconds
      size = 58982400        // bitrate * duration in seconds / 8 bits per byte
      bitrate = 262144       // 256k
      persons = ["Bill Gates", "Steve Jobs"]
      player = JAVA
      copyright = null
   }

   images = [
      Image {
         uri = "http://javaone.com/keynote_large.jpg"
         title = "Javaone Keynote"
         width = 1024
         height = 768
         size = LARGE
      }
      Image {
         uri = "http://javaone.com/keynote_small.jpg"
         title = "Javaone Keynote"
         width = 320
         height = 240
         size = SMALL
      }
   ]

}

```
The data types (“?” indicates an optional value):

```
record Image = {
   uri: String
   title: String?
   width: Int32
   height: Int32
   size: Size

   enum Size = { SMALL, LARGE, }
}

record Media = {
   uri: String
   title: String?
   width: Int32
   height: Int32
   format: String
   duration: Int64
   size: Int64
   bitrate: Int32?
   persons: List<String>
   player: Player
   copyright: String?

   enum Player = { JAVA, FLASH, }
}

record MediaContent = {
   images: List<Image>
   media: Media
}

```

### Results ###


<p>
Create an object, serialize it to a byte array, then deserialize it back to an object and access all fields.<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Total%20Time&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:4880,6318,65642&chds=0,72206.2044&chxt=y&chxl=0:|java-built-in|icegem|dataserializable-manual&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />

</p>
<br>
<p>
Create an object, serialize it to a byte array.<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Serialization%20Time&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:3157,3676,11949&chds=0,13144.28995&chxt=y&chxl=0:|java-built-in|icegem|dataserializable-manual&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />

</p>
<br>
<p>
Serialize the same object (i.e. doesn’t include creation time)<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Serialization%20Time%2Bsame&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:3066,3581,10974&chds=0,12071.73&chxt=y&chxl=0:|java-built-in|icegem|dataserializable-manual&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />

</p>
<br>
<p>
Deserialize an object<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Deserialize%20Time&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:1623,2517,53464&chds=0,58811.464250000005&chxt=y&chxl=0:|java-built-in|icegem|dataserializable-manual&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />

</p>
<br>
<p>
Deserialize an object and access the top-level fields<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Deserialize%20Time%2Bshal&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:1671,2583,53553&chds=0,58908.41715000001&chxt=y&chxl=0:|java-built-in|icegem|dataserializable-manual&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />
</p>
<br>
<p>
Often the most expensive operation. To make a fair comparison, all fields of the deserialized instances are accessed – this forces lazy deserializers to really do their work. The raw data below shows additional measurements for deserialization.<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Deserialization%20Time%2Bdeep&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:1722,2641,53692&chds=0,59061.914450000004&chxt=y&chxl=0:|java-built-in|icegem|dataserializable-manual&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />

</p>
<br>
<p>
The size of the serialized data. These numbers may vary depending on the exact data value being used.<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Serialized%20Size&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:263,278,889&chds=0,977.9000000000001&chxt=y&chxl=0:|java-built-in|icegem|dataserializable-manual&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />

</p>
<br>
<p>
The size of the serialized data compressed with Java’s built-in implementation of DEFLATE (zlib).<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Serialization%20Compressed%20Size&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:156,164,523&chds=0,575.3000000000001&chxt=y&chxl=0:|java-built-in|icegem|dataserializable-manual&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />

</p>
<br>
<p>
Create an object (using the classes specified by the serialization tool)<br>
</p>
<p>
<img src='https://chart.googleapis.com/chart?chtt=Object%20Creation%20Time&chf=c||lg||0||FFFFFF||1||76A4FB||0|bg||s||EFEFEF&chs=700x90&chd=t:122,122,122&chds=0,177.198956&chxt=y&chxl=0:|java-built-in|dataserializable-manual|icegem&chm=N *f*,000000,0,-1,10&lklk&chdlp=t&chco=660000|660033|660066|660099|6600CC|6600FF|663300|663333|663366|663399|6633CC|6633FF|666600|666633|666666&cht=bhg&chbh=10,0,10&nonsense=aaa.png' />

</p>
<br>

<h1>Bucket aware query service</h1>

This service allows to execute OQL queries on a specified set of buckets. The set of buckets is determined by keys of entries that are stored in such buckets:<br>
<ul><li>real and fake keys can be used (such key should have the same routing object as bucket's keys have);<br>
</li><li>it will be enough to specify one key for each bucket.</li></ul>

Bucket oriented query service can be used both on client and server/peer sides.<br>
<br>
<pre><code>public class BucketOrientedQueryService {<br>
    ...<br>
<br>
    public static SelectResults&lt;Object&gt; executeOnBuckets(String queryString, Region region, Set&lt;Object&gt; keys) throws QueryException {<br>
        ...<br>
    }<br>
<br>
    public static SelectResults&lt;Object&gt; executeOnBuckets(String queryString, Object[] queryParameters, Region region, Set&lt;Object&gt; keys) throws QueryException {<br>
        ...<br>
    }<br>
}<br>
</code></pre>

Where:<br>
<ul><li><code>queryString</code> - OQL query string for execute;<br>
</li><li><code>queryParameters</code> - query parameters;<br>
</li><li><code>region</code> - partitioned region on which query will be executed;<br>
</li><li><code>keys</code> - set of keys that specify buckets;</li></ul>

<b>Usage example:</b>

<pre><code>...<br>
SelectResults&lt;Object&gt; results = BucketOrientedQueryService.executeOnBuckets("SELECT * FROM /data WHERE property = $1", new Object[]{1}, data, new HashSet&lt;Object&gt;(Arrays.asList("key1")));<br>
...<br>
</code></pre>
<b>Note:</b> <code>icegem-core.jar</code> should be added to a ClassPath of all members in a distributed system where OQL query will be executed.<br>
<br>
<h1>Paginated Queries</h1>

This component allows to execute paginated queries both from client and peer/server sides. It caches paginated query results in a help region and allows to iterate on them using paginated query API. Paginated query can be created using constructors with different parameters. The full list of parameters can be configured using the following constructor:<br>
<pre><code>PaginatedQuery(QueryService queryService, int queryLimit, Region region, String queryString, Object[] queryParameters, int pageSize);<br>
</code></pre>

<b>Where:</b>

<ul><li><code>queryService</code> - a service to run the query;<br>
</li><li><code>queryLimit</code> - a limit on size of query results (default is 1000 entries)<sup>1</sup>;<br>
</li><li><code>region</code> - a region for querying;<br>
</li><li><code>queryString</code> - a query string<sup>2</sup>;<br>
</li><li><code>queryParameters</code> - parameters for query execution;<br>
</li><li><code>pageSize</code> - a size of page (default is 20).</li></ul>

<sup>1</sup> see a "Limiting of results" section below.<br>
<sup>2</sup> query string has some limitations. See a "Restrictions" section below.<br>
<br>
Query can be parametrized by an entry type. For example, a paginated query for working with a region that contains entries of a type <code>Person</code> can be created this way:<br>
<br>
<pre><code>PaginatedQuery&lt;Person&gt; query = new PaginatedQuery&lt;Person&gt;(...);<br>
</code></pre>

<h2>Requirements</h2>

<ol><li>Member (client or peer/server) that wants to execute paginated queries must have in it's local cache:<br>
<ul><li>region for querying;<br>
</li><li>help region with name <code>PaginatedQuery.PAGINATED_QUERY_INFO_REGION_NAME</code> for storing information about paginated queries. Expiration policy should be configured for this region. This region can be partitioned or replicated and must have the following configuration:<br>
<pre><code>Region&lt;PaginatedQueryPageKey, List&lt;Object&gt;&gt; paginatedQueryInfoRegion;<br>
</code></pre>
</li></ul></li><li>All members that store help region must have <code>icegem-core.jar</code> in it's ClassPath.</li></ol>

<h2>Restrictions</h2>

<ol><li>A query string for paginated query can be arbitrarily complex but entry key must be part of projection list.<br>
</li><li>For partitioned regions a query string must meet the requirements described in a GemFire documentation for querying partitioned regions.</li></ol>

<b>Paginated query object methods:</b>

<ul><li><code>page(int pageNumber)</code> - returns entries for a specified page number;<br>
</li><li><code>getPageSize()</code> - returns size of page (page size is 20 by default);<br>
</li><li><code>getTotalNumberOfPages()</code> - returns a total number of query pages;<br>
</li><li><code>getTotalNumberOfEntries()</code> - returns a total number of query entries;<br>
</li><li><code>isLimitExceeded()</code> - gets value of a flag that indicates excess of query limit;<br>
</li><li><code>pageExists(int pageNumber)</code> - checks that a specified page number exists;</li></ul>

<h2>Ordering of results for partitioned regions</h2>

A paginated query supports order by functionality on partitioned regions.<br>
<br>
<b>Restrictions</b>
<ol><li>The fields specified in the order by clause must be part of the projection list.<br>
</li><li>Query string with order by clause must contain <code>distinct</code> word.</li></ol>

<h2>Limiting of results</h2>

Paginated query result can be limited. By default this limit is 1000 entries. You can specify a custom limit value via paginated query constructor argument. If query results exceeds this limit:<br>
<ul><li>only a specified limit number of entries will be cached and returned;<br>
</li><li>flag <code>limitExceeded</code> will be set to <code>true</code> (method <code>isLimitExceeded()</code> will return true);</li></ul>

<h2>Workflow</h2>

<ol><li>Using one of particular constructors member creates a paginated query based on a specified set of parameters.<br>
</li><li>When the member invokes any of paginated query API methods (except <code>getPageSize()</code>) the query executes and it's results are stored into a help region. It happens only if query execution results have not been saved before. Otherwise query results loaded from the help region.<br>
</li><li>Cached query results can be used during some period of time (depends on configuration of expiration policy for the help region). After this time query information will be expired and next time the query will be executed and results will be cached again.</li></ol>

<h2>Usage example</h2>

Get first page of persons from the region <code>/person</code>:<br>
<pre><code>...<br>
QueryService queryService = cache.getQueryService();<br>
String queryString = "SELECT * FROM /person.keySet";<br>
int pageSize = 10;<br>
PaginatedQuery&lt;Person&gt; query = new PaginatedQuery&lt;Person&gt;(queryService, "person", queryString, pageSize);<br>
if (querty.hasNext()) {<br>
    List&lt;Person&gt; pageEntries = query.page(1);<br>
}<br>
</code></pre>

Get first page of persons with social number = 534 from the region <code>/person</code>:<br>
<pre><code>...<br>
QueryService queryService = cache.getQueryService();<br>
String queryString = "SELECT e.key FROM /person.entrySet e WHERE e.value.socialNumber = $1";<br>
int pageSize = 30;<br>
PaginatedQuery&lt;Person&gt; query = new PaginatedQuery&lt;Person&gt;(queryService, "person", queryString, new Object[]{534}, pageSize);<br>
List&lt;Person&gt; pageEntries = query.page(1);<br>
</code></pre>

Get first page of persons from the region <code>/person</code> ordered by social number with total query limit 400:<br>
<pre><code>...<br>
QueryService queryService = cache.getQueryService();<br>
String queryString = "SELECT DISTINCT d.key, d.value.socialNumber FROM /data.entrySet d ORDER BY d.value.socialNumber";<br>
int pageSize = 10;<br>
int queryLimit = 400;<br>
PaginatedQuery&lt;Person&gt; query = new PaginatedQuery&lt;Person&gt;(queryService, queryLimit, "person", queryString, pageSize);<br>
if (querty.hasNext()) {<br>
    List&lt;Person&gt; pageEntries = query.page(1);<br>
}<br>
</code></pre>

<h1>Smart expiration</h1>

Allows to customize the expiration of region entries. It is possible to define own policy implementing the interface ExpirationPolicy.<br>
<br>
<br>
<h2>Example</h2>

<pre><code><br>
ClientCache cache = ...; <br>
Region dataRegion = ...;<br>
Region errorsRegion = ...;<br>
<br>
ExpirationController expirationController = new ExpirationController();<br>
<br>
long destroyedEntriesNumberForData = expirationController.process(dataRegion,<br>
	new ExpirationPolicy() {<br>
<br>
		public boolean isExpired(Entry&lt;Object, Object&gt; entry) {<br>
			// TODO: Add some logic<br>
			return false;<br>
		}<br>
	});<br>
<br>
long destroyedEntriesNumberForErrors = expirationController.process(errorsRegion,<br>
	new ExpirationPolicy() {<br>
<br>
		public boolean isExpired(Entry&lt;Object, Object&gt; entry) {<br>
			// TODO: Add some logic<br>
			return false;<br>
		}<br>
	});<br>
 <br>
cache.close();<br>
<br>
</code></pre>

<h2>How to get access to other regions using smart expiration</h2>

<pre><code>new ExpirationPolicy() {<br>
<br>
  public boolean isExpired(Entry&lt;Object, Object&gt; entry) {<br>
    RegionService regionService = entry.getRegion().getRegionService();<br>
    Region&lt;Long, TransactionProcessingError&gt; errorsRegion = regionService.getRegion("errors");<br>
<br>
    // TODO: Add some logic<br>
    return false;<br>
  }<br>
});<br>
</code></pre>

<h2>Processing with delays</h2>

The method <code>ExpirationController#process(Region&lt;?, ?&gt; region, ExpirationPolicy policy)</code> can overload the processing node. This can block the other activities.<br>
<br>
In such case it is possible to change the packetSize (the size of the consistently expired entries packet) and packetDelay (the delay in processing after the packetSize entries, milliseconds) using setters of these fields. Example:<br>
<pre><code>ExpirationController expirationController = new ExpirationController();<br>
<br>
expirationController.setPacketSize(1000);<br>
expirationController.setPacketDelay(1000);<br>
<br>
long destroyedEntriesNumberForData = expirationController.process(dataRegion,<br>
	new ExpirationPolicy() {<br>
<br>
		public boolean isExpired(Entry&lt;Object, Object&gt; entry) {<br>
			// TODO: Add some logic<br>
			return false;<br>
		}<br>
	});<br>
</code></pre>


<h1>Cache utils</h1>

Cache utils consists of several utilities which can help with testing, deploying and monitoring of GemFire-related applications.<br>
<br>
This is the list of available commands:<br>
<ul><li>compare<br>
</li><li>monitor<br>
</li><li>update<br>
</li><li>waitfor<br>
</li><li>check-replication</li></ul>

Cache utils also has the possibility to specify GemFire properties as the system properties:<br>
<pre><code>java -Dgemfire.log-level=none -Dgemfire.license-file=C:\bin\GemFire6512\gemfireLicense.zip -Dgemfire.license-type=evaluation -jar icegem-cache-utils-0.8-SNAPSHOT-executable.jar -d check-replication -c clusterA=localhost[18081] -c clusterB=localhost[18082] -c clusterC=localhost[18083] -t 30000<br>
</code></pre>

The JVM arguments <code>-Dgemfire.log-level=none -Dgemfire.license-file=C:\bin\GemFire6512\gemfireLicense.zip -Dgemfire.license-type=evaluation</code> will be trasferred to the following gemfire properties:<br>
<pre><code>log-level=none<br>
license-file=C:\bin\GemFire6512\gemfireLicense.zip<br>
license-type=evaluation<br>
</code></pre>

Also there are options which are common for all the commands and specified next after jar name:<br>
<pre><code>D:\Temp&gt;java -jar icegem-cache-utils-0.8-SNAPSHOT-executable.jar<br>
usage: java -jar icegem-cache-utils-&lt;version&gt;.jar [options] &lt;compare |<br>
            monitor | check-replication | update | waitfor&gt;<br>
            [command_specific_options]<br>
 -d,--debug   Print debug information<br>
 -h,--help    Print usage information<br>
 -q,--quiet   Quiet output. Doesn't work if --debug specified.<br>
</code></pre>
<a href='Hidden comment: 
compare

Compares data of the specified region in specified cache servers (mode REPLICATION) or specified locators of the same cluster. It is also possible to provide list of java packages to restrict comparison.

=== Result of comparison ===

Result of comparison - list of the results for the each checked node. For each node there is complex object which contains:
* set of missing keys (set of all keys minus set of local keys)
* set of extra keys (set of local keys minus set of all keys)
* set of different keys (key is present in both sets - local and all, but values are different)
* node identifier

=== Usage help ===

This is the application help for the command "comparator":

<pre><code>D:\Temp\icegem-cache-utils-0.7-SNAPSHOT>java -jar icegem-cache-utils-0.7-SNAPSHOT.jar comparator
usage: comparator
 -c,--packages <arg>   Enumerate packages to scan for @AutoSerializable
                       model classes. Delimiter is a comma sign.
 -h,--help             Print usage information
 -l,--locators <arg>   Locators of GemFire system. For intra-cluster
                       checking. Example: host1[port1],host2[port2]
 -p,--path <arg>       Region path to be compared. Only replicated region
                       could be used. Example: /region1/region2
 -s,--servers <arg>    Servers of GemFire system. For multi-cluster
                       systems. Example: host1[port1],host2[port2]
</code></pre>

The following command will start comparator utility. Replicated region with path "/data" will be compared on the cache servers localhost[40402],localhost[40403] and localhost[40405] :

<pre><code>java -jar icegem-cache-utils-0.7-SNAPSHOT.jar comparator -p /data -s localhost[40402],localhost[40403],localhost[40405]
</code></pre>
'></a><br>
<br>
<h2>monitor</h2>

In addition to JMX agent monitor command is able to detect deadlocks of cache servers and provide hooks for custom handlers.<br>
<br>
<h3>Configuration</h3>

All the configuration of the monitoring tool is in the two property files:<br>
<ul><li>monitoring.properties - the main configuration file which points the tool to the GemFire network, sets delay and period, configures email texts and setups the email SMTP server settings<br>
</li><li>log4j.properties - configures logging</li></ul>

<h3>Usage help</h3>

This is the application help for the command "monitor":<br>
<br>
<pre><code>D:\Temp&gt;java -jar icegem-cache-utils-0.8-SNAPSHOT-executable.jar monitor<br>
usage: monitor &lt;--help | --server [--timeout] | --all &lt;--locators&gt;<br>
               [--period] [--timeout] &gt;<br>
 -a,--all              Periodically check all the servers related to<br>
                       locators specified in monitoring.properties file<br>
 -h,--help             Print usage information<br>
 -l,--locators &lt;arg&gt;   List of locators in format<br>
                       host1[port1],host2[port2]<br>
 -p,--period &lt;arg&gt;     Period between runs, ms. Default value is 10000<br>
 -s,--server &lt;arg&gt;     Check one server and exit with status 0 if server<br>
                       alive, or with status 1 if server is dead or down.<br>
                       Server should be in format host[port].<br>
 -t,--timeout &lt;arg&gt;    Timeout, ms. Default value is 3000<br>
</code></pre>

Examples of usage:<br>
<pre><code>java -jar icegem-cache-utils-0.7-SNAPSHOT.jar monitor -s localhost[40404]<br>
</code></pre>
Checks that server on host=localhost and port=40404 is alive. Returns exit code <code>0</code> in case of the server alive, 1 in case of its down, -1 in case of there is some other error like misconfiguration.<br>
<br>
<br>
<pre><code>java -jar icegem-cache-utils-0.7-SNAPSHOT.jar monitor -a -l localhost[10355]<br>
</code></pre>
Monitor will check periodically all the servers related to locator <code>localhost[10355]</code>, write to console and log file, and also will send alert messages.<br>
<br>
<h2>update</h2>

The command traverses region and simply gets the value for each entry of the region and puts it back to the same key. This is required to upgrade binary form of object in persistent storage to format used by the currently deployed code.<br>
<br>
While this can be done in run-time, if any problem occurs, system lock down can happen. So the update has to be done before go live.<br>
<br>
<h3>Usage help</h3>

This is the application help for the command "updater":<br>
<pre><code>D:\Temp\icegem-cache-utils-0.7-SNAPSHOT&gt;java -jar icegem-cache-utils-0.7-SNAPSHOT.jar updater<br>
usage: updater<br>
 -a,--all              Update all regions in system<br>
 -c,--subregions       Indicate whether to update all subregions of<br>
                       mentioned regions<br>
 -h,--help             Print usage information<br>
 -l,--locator &lt;arg&gt;    Locator of GemFire system. Example: host[port]<br>
 -p,--packages &lt;arg&gt;   Enumerate packages to scan for @AutoSerializable<br>
                       model classes. Delimiter is a comma sign.<br>
 -r,--regions &lt;arg&gt;    Enumerate regions to be updated here. Delimiter is<br>
                       a comma sign. Example: region1,region2,region3...<br>
 -s,--server &lt;arg&gt;     Server of GemFire system. Example: host[port]<br>
</code></pre>

Examples of usage:<br>
<pre><code>java -jar icegem-cache-utils-0.7-SNAPSHOT.jar updater -a -l localhost[10355] -s localhost[40404]<br>
</code></pre>
This will cause updater to update all regions in distributed system with locator <code>localhost[10355]</code> and cache server <code>localhost[40404]</code>
<pre><code>java -jar icegem-cache-utils-0.7-SNAPSHOT.jar updater -r region1,region2 -c -l localhost[10355] -s localhost[40404]<br>
</code></pre>
This will cause updater to update regions region1 and region2 with all its' subregions in distributed system with locator <code>localhost[10355]</code> and cache server <code>localhost[40404]</code>

<h2>waitfor</h2>

Wait appearance of an object in a region<br>
<br>
<h3>Usage help</h3>

<pre><code>java -jar icegem-cache-utils-*-SNAPSHOT.jar signal<br>
-region regionName     where needed key will appear<br>
-locators              locator(s) list in format host[port],..<br>
-key                   key value, that will appear in signal region (java.lang.String)<br>
-timeout               how long utility will check region, in millis (default: 60sec)<br>
-checkInterval         in what period utility will check region, in millis (default: 1 sec)<br>
</code></pre>
Example:<br>
<br>
<pre><code>java -jar icegem-cache-utils-0.7-SNAPSHOT.jar signal -region signalRegion -locators localhost[10334],localhost[10355] -key signalKey<br>
</code></pre>

<h2>check-replication</h2>

Checks that WAN replication works between the specified clusters. Also measures and prints latency for each replication link.  Due the chosen measurement method the displayed values give higher threshold for latency which can be significantly shorter.<br>
<br>
<h3>Usage help</h3>

This is the application help for the command "replication":<br>
<br>
<pre><code>D:\Temp&gt;java -jar icegem-cache-utils-0.8-SNAPSHOT-executable.jar check-replication<br>
usage: check-replication [options]<br>
 -c,--cluster &lt;cluster=locators&gt;   Cluster name and list of its locators.<br>
                                   There should be at least two clusters.<br>
                                   Example: -c<br>
                                   cluster1=locator1[port1],locator2[port2] -c<br>
                                   cluster2=host3[port3]<br>
 -h,--help                         Print usage information<br>
 -r,--region &lt;arg&gt;                 The name of region for this test.<br>
                                   Default name is "proxy"<br>
 -t,--timeout &lt;arg&gt;                Timeout, ms. Default timeout is 60000<br>
</code></pre>

Examples of usage:<br>
<br>
<pre><code>java -Dgemfire.log-level=none -Dgemfire.license-file=C:\bin\GemFire6512\gemfireLicense.zip -Dgemfire.license-type=evaluation -jar icegem-cache-utils-0.8-SNAPSHOT-executable.jar check-replication -c clusterA=localhost[18081] -c clusterB=localhost[18082] -c clusterC=localhost[18083] -t 10000<br>
</code></pre>

Replication tool will check replication for the clusters with locators <code>localhost[18081]</code>, <code>localhost[18082]</code> and <code>localhost[18083]</code>. In case of replication works in all directions, the tool will print time of replication and return exit code 0.<br>
<br>
<pre><code>clusterA &lt;= [clusterB, 956ms][clusterC, 1242ms]<br>
clusterC &lt;= [clusterB, 722ms][clusterA, 590ms]<br>
clusterB &lt;= [clusterC, 1054ms][clusterA, 177ms]<br>
</code></pre>

In case of replication doesn't work it will automatically finish in 10 seconds and return exit code 1.<br>
<br>
<pre><code>clusterA &lt;= [clusterC, 468ms][clusterB, 751ms]<br>
Connection process is not finished for clusterB<br>
clusterC &lt;= [clusterA, 556ms][clusterB, 684ms]<br>
</code></pre>